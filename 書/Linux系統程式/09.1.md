## Linux 多媒體編程的基本概念

Linux 多媒體編程主要涉及到以下三個方面的基本概念：

1. 多媒體格式：Linux平台支持多種多媒體格式，如MP3、OGG、AVI、MKV等。編程時需要了解這些格式及其相關特點，選擇合適的解碼器進行解碼。

2. 多媒體編解碼器：多媒體編解碼器是用於對多媒體數據進行編解碼的軟件，例如FFmpeg、GStreamer等。在Linux平台上，一般使用這些編解碼器進行多媒體處理。

3. 多媒體播放器：多媒體播放器是用於播放多媒體內容的軟件。Linux平台上較為常見的有MPlayer、VLC、Totem等。這些播放器通常使用相應的編解碼器進行解碼，同時支持多種媒體格式和編碼方式。

以下是一個簡單的C語言程式範例，示範如何使用FFmpeg進行視頻解碼並播放。

```c
#include <stdio.h>
#include <unistd.h>
#include <stdlib.h>
#include <string.h>
#include <libavcodec/avcodec.h>
#include <libavformat/avformat.h>
#include <libavutil/avutil.h>
#include <libswscale/swscale.h>
#include <SDL/SDL.h>

int main(int argc, char *argv[]) {
    AVFormatContext *pFormatCtx;
    AVCodecContext *pCodecCtxOrig;
    AVCodecContext *pCodecCtx;
    AVCodec *pCodec;
    AVFrame *pFrame;
    AVFrame *pFrameRGB;
    uint8_t *buffer;
    struct SwsContext *sws_ctx;
    SDL_Surface *screen;
    SDL_Overlay *bmp;
    SDL_Rect rect;
    AVPacket packet;
    int i, videoStream, numBytes;
    int ret;
    int got_picture;
    int width;
    int height;

    if(argc < 2) {
        fprintf(stderr, "Usage: %s file\n", argv[0]);
        return -1;
    }

    // 初始化FFmpeg
    av_register_all();

    // 打開視頻文件（通過AVFormatContext對象）
    if(avformat_open_input(&pFormatCtx, argv[1], NULL, NULL) != 0) {
        return -1;
    }

    // 檢索流信息
    if(avformat_find_stream_info(pFormatCtx, NULL) < 0) {
        return -1;
    }

    // 打印文件信息
    av_dump_format(pFormatCtx, 0, argv[1], 0);

    // 找到第一個視頻流
    videoStream = -1;
    for(i = 0; i < pFormatCtx->nb_streams; i++) {
        if(pFormatCtx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
            videoStream = i;
            break;
        }
    }
    if(videoStream == -1) {
        return -1; 
    }

    // 通過視頻流信息設置編解碼Context
    pCodecCtxOrig = pFormatCtx->streams[videoStream]->codec;
    pCodec = avcodec_find_decoder(pCodecCtxOrig->codec_id);
    if(pCodec == NULL) {
        fprintf(stderr, "Unsupported codec!\n");
        return -1;
    }
    pCodecCtx = avcodec_alloc_context3(pCodec);
    avcodec_copy_context(pCodecCtx, pCodecCtxOrig);
    if(avcodec_open2(pCodecCtx, pCodec, NULL) < 0) {
        return -1;
    }

    // 分配Frame結構體
    pFrame = av_frame_alloc();
    pFrameRGB = av_frame_alloc();
    if(pFrameRGB == NULL || pFrame == NULL) {
        return -1;
    }

    // 計算RGBA存儲空間大小
    numBytes = av_image_get_buffer_size(AV_PIX_FMT_RGB24, pCodecCtx->width, pCodecCtx->height, 1);
    buffer = (uint8_t *)av_malloc(numBytes * sizeof(uint8_t));
    av_image_fill_arrays(pFrameRGB->data, pFrameRGB->linesize, buffer, AV_PIX_FMT_RGB24, pCodecCtx->width, pCodecCtx->height, 1);

    // 初始化SWS Context
    sws_ctx = sws_getContext(pCodecCtx->width, pCodecCtx->height, pCodecCtx->pix_fmt, pCodecCtx->width, pCodecCtx->height, AV_PIX_FMT_RGB24, SWS_BILINEAR, NULL, NULL, NULL);
    if(sws_ctx == NULL) {
        fprintf(stderr, "SWS Context init fail!\n");
        return -1;
    }

    // 初始化SDL
    if(SDL_Init(SDL_INIT_VIDEO | SDL_INIT_AUDIO | SDL_INIT_TIMER)) {
        fprintf(stderr, "SDL init fail!\n");
        return -1;
    }

    // 初始化SDL視窗
    screen = SDL_SetVideoMode(pCodecCtx->width, pCodecCtx->height, 0, 0);
    if(screen == NULL) {
        fprintf(stderr, "SDL set video mode fail!\n");
        return -1;
    }

    bmp = SDL_CreateYUVOverlay(pCodecCtx->width, pCodecCtx->height, SDL_YV12_OVERLAY, screen);

    // 開始播放
    while(av_read_frame(pFormatCtx, &packet) >= 0) {
        if(packet.stream_index == videoStream) {
            avcodec_decode_video2(pCodecCtx, pFrame, &got_picture, &packet);
            if(got_picture) {
                sws_scale(sws_ctx, (const uint8_t * const*)pFrame->data, pFrame->linesize, 0, pCodecCtx->height, pFrameRGB->data, pFrameRGB->linesize);
                SDL_LockYUVOverlay(bmp);
                memcpy(bmp->pixels[0], pFrameRGB->data[0], pCodecCtx->width * pCodecCtx->height);
                memcpy(bmp->pixels[2], pFrameRGB->data[1], pCodecCtx->width * pCodecCtx->height / 4);
                memcpy(bmp->pixels[1], pFrameRGB->data[2], pCodecCtx->width * pCodecCtx->height / 4);
                SDL_UnlockYUVOverlay(bmp);
                rect.x = 0;
                rect.y = 0;
                rect.w = pCodecCtx->width;
                rect.h = pCodecCtx->height;
                SDL_DisplayYUVOverlay(bmp, &rect);
            }
        }
        av_packet_unref(&packet);
        SDL_Delay(30);
    }

    // 回收資源
    av_free(buffer);
    av_frame_free(&pFrameRGB);
    av_frame_free(&pFrame);
    avcodec_close(pCodecCtx);
    avcodec_close(pCodecCtxOrig);
    avformat_close_input(&pFormatCtx);

    SDL_Quit();
    return 0;
}
```