#

```cpp
#include <stdio.h>
#include <string.h>
#include <ctype.h>

#define TMAX 10000000
#define SMAX 100000

enum { Id, Int, Keyword, Literal, Char };

char *typeName[5] = {"Id", "Int", "Keyword", "Literal", "Char"};

char code[TMAX];
char strTable[TMAX], *strTableEnd=strTable;
char *tokens[TMAX];
int tokenTop=0;
int types[TMAX];

#define isDigit(ch) ((ch) >= '0' && (ch) <='9')

#define isAlpha(ch) (((ch) >= 'a' && (ch) <='z') || ((ch) >= 'A' && (ch) <= 'Z'))

int readText(char *fileName, char *text, int size) {
  FILE *file = fopen(fileName, "r");
  int len = fread(text, 1, size, file);
  text[len] = '\0';
  fclose(file);
  return len;
}

/* strTable =
#\0include\0"sum.h"\0int\0main\0.....
*/
char *next(char *p) {
  while (isspace(*p)) p++;

  char *start = p; //         include "sum.h"
                   //         ^      ^
                   //  start= p      p
  int type;
  if (*p == '\0') return NULL;
  if (*p == '"') {
    p++;
    while (*p != '"') p++;
    p++;
    type = Literal;
  } else if (*p >='0' && *p <='9') { // 數字
    while (*p >='0' && *p <='9') p++;
    type = Int;
  } else if (isAlpha(*p) || *p == '_') { // 變數名稱或關鍵字
    while (isAlpha(*p) || isDigit(*p) || *p == '_') p++;
    type = Id;
  } else { // 單一字元
    p++;
    type = Char;
  }
  int len = p-start;
  char *token = strTableEnd;
  strncpy(strTableEnd, start, len);
  strTableEnd[len] = '\0';
  strTableEnd += (len+1);
  types[tokenTop] = type;
  tokens[tokenTop++] = token;
  printf("token=%s\n", token);
  return p;
}

void lex(char *code) {
  char *p = code;
  while (1) {
    p = next(p);
    if (p == NULL) break;
  }
}

void dump(char *strTable[], int top) {
  for (int i=0; i<top; i++) {
    printf("%d:%s\n", i, strTable[i]);
  }
}

int main(int argc, char * argv[]) {
  readText(argv[1], code, sizeof(code)-1);
  puts(code);
  lex(code);
  dump(tokens, tokenTop);
}
```

這是一個 C 語言的 lexer 程式，可以將一段程式碼拆解成一個個的 token（詞彙）。

程式碼主要由以下幾部分組成：

1. 头文件宣告及宏定义：包含了需要使用的头文件和一些常量定义。

2. typeName：一個字符串数组，用于保存 token 的类型名称。

3. code、strTable 和 tokens：三個字符数组，分别用于保存原始程式碼、词汇表和 token 数组。

4. types 和 tokenTop：一个整形数组和一个整型变量，分别用于保存每个 token 的类型和 token 数组的长度。

5. readText 函数：读取指定文件中的文本内容，并返回文本长度。

6. next 函数：读取下一个 token。该函数的输入参数是一个指向字符串的指针 p，函数返回值是下一个 token 的地址。

7. lex 函数：从头到尾遍历 code 字符串，调用 next 函数读取每个 token。

8. dump 函数：输出词汇表中的所有 token。

在 next 函数中，首先跳过字符串开头的空格，然后根据第一个字符的不同，将 token 分为四种类型：字符串（Literal）、数字（Int）、变量名或关键字（Id）和单个字符（Char）。在将 token 加入词汇表（strTable）和 token 数组（tokens）之前，先保存该 token 的类型到 types 数组中。

在 main 函数中，读取指定文件的文本内容，调用 lex 函数将原始程式碼转换为 token 数组，并输出该数组。

注意，该程式碼是示範性質，並非完整的 lexer 實作，實際的 lexer 實作可能還需要進行更多的處理和優化。
